{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20caaeb8",
   "metadata": {},
   "source": [
    "# Домашнее задание №6 Чебыкина Артёма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d832fc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3db28412",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from nltk.stem.porter import *\n",
    "from stop_words import get_stop_words\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff929e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee9c33a",
   "metadata": {},
   "source": [
    "### №1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92da40fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataSet = pd.read_csv(\"data/singapore_airlines_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c51c561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>published_date</th>\n",
       "      <th>published_platform</th>\n",
       "      <th>rating</th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>helpful_votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-03-12T14:41:14-04:00</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>3</td>\n",
       "      <td>review</td>\n",
       "      <td>We used this airline to go from Singapore to L...</td>\n",
       "      <td>Ok</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-03-11T19:39:13-04:00</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>5</td>\n",
       "      <td>review</td>\n",
       "      <td>The service on Singapore Airlines Suites Class...</td>\n",
       "      <td>The service in Suites Class makes one feel lik...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-03-11T12:20:23-04:00</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>1</td>\n",
       "      <td>review</td>\n",
       "      <td>Booked, paid and received email confirmation f...</td>\n",
       "      <td>Don’t give them your money</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-03-11T07:12:27-04:00</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>5</td>\n",
       "      <td>review</td>\n",
       "      <td>Best airline in the world, seats, food, servic...</td>\n",
       "      <td>Best Airline in the World</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-03-10T05:34:18-04:00</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>2</td>\n",
       "      <td>review</td>\n",
       "      <td>Premium Economy Seating on Singapore Airlines ...</td>\n",
       "      <td>Premium Economy Seating on Singapore Airlines ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              published_date published_platform  rating    type  \\\n",
       "0  2024-03-12T14:41:14-04:00            Desktop       3  review   \n",
       "1  2024-03-11T19:39:13-04:00            Desktop       5  review   \n",
       "2  2024-03-11T12:20:23-04:00            Desktop       1  review   \n",
       "3  2024-03-11T07:12:27-04:00            Desktop       5  review   \n",
       "4  2024-03-10T05:34:18-04:00            Desktop       2  review   \n",
       "\n",
       "                                                text  \\\n",
       "0  We used this airline to go from Singapore to L...   \n",
       "1  The service on Singapore Airlines Suites Class...   \n",
       "2  Booked, paid and received email confirmation f...   \n",
       "3  Best airline in the world, seats, food, servic...   \n",
       "4  Premium Economy Seating on Singapore Airlines ...   \n",
       "\n",
       "                                               title  helpful_votes  \n",
       "0                                                 Ok              0  \n",
       "1  The service in Suites Class makes one feel lik...              0  \n",
       "2                         Don’t give them your money              0  \n",
       "3                          Best Airline in the World              0  \n",
       "4  Premium Economy Seating on Singapore Airlines ...              0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataSet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9327af1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ImportantDataSet = DataSet[[\"text\",\"title\",\"rating\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d88d31e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We used this airline to go from Singapore to L...</td>\n",
       "      <td>Ok</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The service on Singapore Airlines Suites Class...</td>\n",
       "      <td>The service in Suites Class makes one feel lik...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Booked, paid and received email confirmation f...</td>\n",
       "      <td>Don’t give them your money</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Best airline in the world, seats, food, servic...</td>\n",
       "      <td>Best Airline in the World</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Premium Economy Seating on Singapore Airlines ...</td>\n",
       "      <td>Premium Economy Seating on Singapore Airlines ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  We used this airline to go from Singapore to L...   \n",
       "1  The service on Singapore Airlines Suites Class...   \n",
       "2  Booked, paid and received email confirmation f...   \n",
       "3  Best airline in the world, seats, food, servic...   \n",
       "4  Premium Economy Seating on Singapore Airlines ...   \n",
       "\n",
       "                                               title  rating  \n",
       "0                                                 Ok       3  \n",
       "1  The service in Suites Class makes one feel lik...       5  \n",
       "2                         Don’t give them your money       1  \n",
       "3                          Best Airline in the World       5  \n",
       "4  Premium Economy Seating on Singapore Airlines ...       2  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ImportantDataSet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a53d151",
   "metadata": {},
   "outputs": [],
   "source": [
    "ImportantDataSet['full_review'] = ImportantDataSet['title'] + \" \" + ImportantDataSet['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5dbe2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ImportantDataSet = ImportantDataSet[[\"full_review\",\"rating\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "949c0400",
   "metadata": {},
   "outputs": [],
   "source": [
    "UnprocessedDataSet = ImportantDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cb07184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ok We used this airline to go from Singapore t...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The service in Suites Class makes one feel lik...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Don’t give them your money Booked, paid and re...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Best Airline in the World Best airline in the ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Premium Economy Seating on Singapore Airlines ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         full_review  rating\n",
       "0  Ok We used this airline to go from Singapore t...       3\n",
       "1  The service in Suites Class makes one feel lik...       5\n",
       "2  Don’t give them your money Booked, paid and re...       1\n",
       "3  Best Airline in the World Best airline in the ...       5\n",
       "4  Premium Economy Seating on Singapore Airlines ...       2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ImportantDataSet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebfccf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(x):\n",
    "    res = []\n",
    "    for word in x.lower().split():\n",
    "        for sign in string.punctuation:\n",
    "            word = word.replace(sign, '')\n",
    "        res.append(word)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f1fe4b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [ok, we, used, this, airline, to, go, from, si...\n",
       "1       [the, service, in, suites, class, makes, one, ...\n",
       "2       [don’t, give, them, your, money, booked, paid,...\n",
       "3       [best, airline, in, the, world, best, airline,...\n",
       "4       [premium, economy, seating, on, singapore, air...\n",
       "                              ...                        \n",
       "9995    [flew, to, nz, 1st, half, singapore, airlines,...\n",
       "9996    [best, airline, and, again, a, great, flight, ...\n",
       "9997    [superb, service, on, singapore, airlines, we,...\n",
       "9998    [a, comfortable, fiight, spoiled, by, lack, of...\n",
       "9999    [delivered, as, expected, , as, always, singap...\n",
       "Name: full_review, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ImportantDataSet['full_review'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "049f8e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(ImportantDataSet, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5274464f",
   "metadata": {},
   "source": [
    "Разделим выборку, и применим метод Bag of Words и TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c850ffdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = CountVectorizer()\n",
    "x_train = bow.fit_transform(train['full_review'])\n",
    "x_test = bow.transform(test['full_review'])\n",
    "y_train = train['rating']\n",
    "y_test = test['rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7defe620",
   "metadata": {},
   "source": [
    "Запустим логистическую регрессию, проверив ее с помощью F1 score, подсчитанного для нескольких классов(оценки 1-5) с помощью Micro averaged F1 Score, чтобы учесть разные метрики."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2633394",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3f9b088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6748"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "f1_score(y_pred, y_test,average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "846ea2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = TfidfVectorizer()\n",
    "x_train = tf_idf.fit_transform(train['full_review'])\n",
    "x_test = tf_idf.transform(test['full_review'])\n",
    "y_train = train['rating']\n",
    "y_test = test['rating']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0444d243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7056"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "f1_score(y_pred, y_test, average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a0def2",
   "metadata": {},
   "source": [
    "Модель TF-IDF отработала немного лучше"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a60a21",
   "metadata": {},
   "source": [
    "### №2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb6b508",
   "metadata": {},
   "source": [
    "Создадим Пайплайн по похожей на практику схеме, чтобы протестировать разные комбинации моделей для получения наилучшего результата"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72fa3004",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasePreprocessor(BaseEstimator):\n",
    "    \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, x):\n",
    "        return np.array(list(map(lambda x: ' '.join(preprocess_text(x)), x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "002a3be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49dd8355",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = list(get_stop_words('en'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73abfd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def better_preprocess_text(x,mode):\n",
    "    res = []\n",
    "    for word in x.lower().split():\n",
    "        if word not in stop_words:\n",
    "            for sign in string.punctuation:\n",
    "                word = word.replace(sign, '')\n",
    "            res.append(word)\n",
    "    if mode:\n",
    "        return ' '.join(map(stemmer.stem, res))\n",
    "    else: return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6c7ff04",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StemPreprocessor(BaseEstimator):\n",
    "    \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def _stem(self, word):\n",
    "        return stemmer.stem(word)\n",
    "    \n",
    "    def _transform_text(self, text):\n",
    "        return better_preprocess_text(text,1)\n",
    "\n",
    "    def transform(self, x):\n",
    "        return list(map(self._transform_text, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067a9d4f",
   "metadata": {},
   "source": [
    "Не забудем разделить выборку на необработанном датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df10d5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(UnprocessedDataSet, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3360bc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_results = []\n",
    "\n",
    "x_train = train['full_review']\n",
    "x_test = test['full_review']\n",
    "y_train = train['rating']\n",
    "y_test = test['rating']\n",
    "\n",
    "for vect in [CountVectorizer(), TfidfVectorizer()]:\n",
    "    for model in [LogisticRegression(max_iter=1000), RandomForestClassifier()]:\n",
    "        pipeline = Pipeline(\n",
    "            [\n",
    "                (\"base\", BasePreprocessor()),\n",
    "                (\"stem\", StemPreprocessor()),\n",
    "                (\"vect\", vect),\n",
    "                (\"model\", model),\n",
    "            ]\n",
    "        )\n",
    "        pipeline.fit(x_train, y_train)\n",
    "        y_pred = pipeline.predict(x_test)\n",
    "        metric = f1_score(y_pred, y_test, average='micro')\n",
    "        fit_results.append(\n",
    "            {\n",
    "                'vect': vect.__class__.__name__,\n",
    "                'model': model.__class__.__name__,\n",
    "                'f1': metric,\n",
    "            }\n",
    "        )\n",
    "\n",
    "fit_results = pd.DataFrame(fit_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc139acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              vect                   model      f1\n",
      "0  CountVectorizer      LogisticRegression  0.6664\n",
      "1  CountVectorizer  RandomForestClassifier  0.6288\n",
      "2  TfidfVectorizer      LogisticRegression  0.7000\n",
      "3  TfidfVectorizer  RandomForestClassifier  0.6264\n"
     ]
    }
   ],
   "source": [
    "print(fit_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e7cf0d",
   "metadata": {},
   "source": [
    "Модель TF-IDF с логистической регрессией отработала лучше всех, а с Лесом наоборот хуже(хотя по сути почти также как BOW). Можно увидеть что на таких жанных логистическая регрессия даёт более хороший результат."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a218914c",
   "metadata": {},
   "source": [
    "Напишем один коментарий на оценку 2 и один на оценку 5:\n",
    "\n",
    "2 : \"Meh\" - \"The only good thing about this flight was the fact, that we have reached the destination. The food, we were served was stale, and none of the crew seemed to care about passengers or anything for that matter.\"\n",
    "\n",
    "5: \"Fantastic\" - \"The flight was great. I appreciated the fact, that the crew was friendly. Both descending and landing were very smooth, which was a very pleasant thing as well.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "17969011",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bad_comment = \"Meh The only good thing about this flight was the fact, that we have reached the destination. The food, we were served was stale, and none of the crew seemed to care about passengers or anything for that matter.\"\n",
    "Good_comment = \"Fantastic The flight was great. I appreciated the fact, that the crew was friendly. Both descending and landing were very smooth, which was a very pleasant thing as well.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3bc46dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "BadProcessed = tf_idf.transform(better_preprocess_text(Bad_comment,0))\n",
    "GoodProcessed = tf_idf.transform(better_preprocess_text(Good_comment,0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e93d161",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 17353 features, but RandomForestClassifier is expecting 15291 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBad comment:\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBadProcessed\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBad comment:\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(model\u001b[38;5;241m.\u001b[39mpredict(GoodProcessed)))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:820\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    799\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    800\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;124;03m    Predict class for X.\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[38;5;124;03m        The predicted classes.\u001b[39;00m\n\u001b[0;32m    819\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 820\u001b[0m     proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    823\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39margmax(proba, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:862\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    860\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    861\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[1;32m--> 862\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_X_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m    865\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:602\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    599\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    600\u001b[0m \u001b[38;5;124;03mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[0;32m    601\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 602\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[0;32m    604\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:569\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    566\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 569\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:370\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 370\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    371\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    372\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    373\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 17353 features, but RandomForestClassifier is expecting 15291 features as input."
     ]
    }
   ],
   "source": [
    "print(\"Bad comment:\" + str(model.predict(BadProcessed)))\n",
    "\n",
    "print(\"Bad comment:\" + str(model.predict(GoodProcessed)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a505fec",
   "metadata": {},
   "source": [
    "Простая модель оба комментария оценила хорошо, скорее всего из-за того, что не является слишком продвуинутой, а в плохом коментарии я использовал слова, которые часто имеют и положительное значение"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
